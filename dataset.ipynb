{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from lib.data import get_all_csv_files, large_df, make_dataset, scale, inverse_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_all_csv_files('./stock_market_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4280/4280 [01:25<00:00, 50.12it/s] \n"
     ]
    }
   ],
   "source": [
    "df = large_df(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Low', 'Open', 'High', 'Close', 'Volume']].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Low'] < 5e3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gzip, json, shutil, torch, pickle\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(Dataset):\n",
    "    def __init__(self, time_d: int = 10, output_params: int = 4):\n",
    "        self.time_d = time_d\n",
    "        self.output_params = output_params\n",
    "\n",
    "        self.max_low = 5e3\n",
    "        self.cols = ['Low', 'Open', 'High', 'Close', 'Volume']\n",
    "        self.compressed = False\n",
    "\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "        self.scl = {\n",
    "            'money': (0.0, 1.0),\n",
    "            'volume': (0.0, 1.0),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return 0 if type(self.X) == type(None) else len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def ticker_from_path(path: str):\n",
    "        return os.path.basename(path)[:-4]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_all_csv_files(dir: str):\n",
    "        files = []\n",
    "        a = os.listdir(dir)\n",
    "        for b in a:\n",
    "            if os.path.isdir(os.path.join(dir, b)):\n",
    "                c = os.path.join(dir, b, 'csv')\n",
    "                if os.path.isdir(c):\n",
    "                    files += [os.path.join(c, f) for f in os.listdir(c) if f[-4:] == '.csv']\n",
    "\n",
    "        return files\n",
    "\n",
    "    @staticmethod\n",
    "    def to_tensors(d):\n",
    "        return torch.from_numpy(np.array(d))\n",
    "\n",
    "    def find_ranges(self):\n",
    "        money = self.X[:, :-1]\n",
    "        volume = self.X[:, -1:]\n",
    "\n",
    "        self.scl['money'] = (float(torch.min(money)), float(torch.max(money)))\n",
    "        self.scl['volume'] = (float(torch.min(volume)), float(torch.max(volume)))\n",
    "\n",
    "    def scale(self, data: torch.Tensor, new_min=0, new_max=1, with_volume: bool = True):\n",
    "        money = data[:, :4] if with_volume else data\n",
    "        money = (money - self.scl['money'][0]) / (self.scl['money'][1] - self.scl['money'][0]) * (new_max - new_min) + new_min\n",
    "        \n",
    "        if not with_volume:\n",
    "            return money\n",
    "\n",
    "        volume = (data[:, -1:] - self.scl['volume'][0]) / (self.scl['volume'][1] - self.scl['volume'][0]) * (new_max - new_min) + new_min\n",
    "        return torch.hstack((money, volume))\n",
    "\n",
    "    def inverse_scale(self, data: torch.Tensor, curr_max = 1, with_vol: bool = False):\n",
    "        money = data[:, :-1] if with_vol else data\n",
    "        money = money / curr_max * (self.scl['money'][1] - self.scl['money'][0]) + self.scl['money'][0]\n",
    "\n",
    "        if not with_vol:\n",
    "            return money\n",
    "        \n",
    "        volume = data[:, -1:] / curr_max * (self.scl['volume'][1] - self.scl['volume'][0]) + self.scl['volume'][0]\n",
    "        return torch.hstack((money, volume))\n",
    "\n",
    "    def make_dataset(self, d: List[List[float]]):\n",
    "        d: torch.Tensor = self.to_tensors(d)\n",
    "        Xd, yd = None, None\n",
    "\n",
    "        for i in range(d.shape[0] - self.time_d - 1):\n",
    "            idx = i + self.time_d\n",
    "            row = d[idx + 1]\n",
    "            row = row[:-1] # remove volume is it doesn't need to be predicted\n",
    "            x = d[i:idx]\n",
    "            if torch.isnan(torch.sum(x)) or torch.isnan(torch.sum(row)):\n",
    "                continue # if the row (y) has nans, skip\n",
    "\n",
    "            if type(Xd) == type(None):\n",
    "                Xd = x\n",
    "                yd = row\n",
    "            else:\n",
    "                Xd = torch.concat((Xd, x))\n",
    "                yd = torch.concat((yd, row))\n",
    "            \n",
    "        return Xd, yd\n",
    "\n",
    "    def make_datasets(self, data: dict):\n",
    "        loop = tqdm(data, total=len(data), leave=False)\n",
    "        for ticker in loop:\n",
    "            # to_dataset\n",
    "            dataset = self.make_dataset(data[ticker])\n",
    "\n",
    "            # checks\n",
    "            if type(dataset[0]) == type(None) or type(dataset[1]) == type(None):\n",
    "                print(f\"{ticker} is useless when using time_d {self.time_d}\")\n",
    "                continue\n",
    "\n",
    "            # add to large dataset\n",
    "            if type(self.X) == type(None):\n",
    "                self.X = dataset[0]\n",
    "                self.y = dataset[1]\n",
    "            else:\n",
    "                self.X = torch.concat((self.X, dataset[0]))\n",
    "                self.y = torch.concat((self.y, dataset[1]))\n",
    "\n",
    "        # scale\n",
    "        self.find_ranges()\n",
    "        self.X = self.scale(self.X)\n",
    "        self.y = self.scale(self.y, with_volume=False)\n",
    "\n",
    "    def large_df(self, path):\n",
    "        files = self.get_all_csv_files(path)\n",
    "        return pd.concat((pd.read_csv(f) for i, f in tqdm(enumerate(files), total=len(files), leave=False)), ignore_index=True)\n",
    "\n",
    "    def filter_data(self, df: pd.DataFrame):\n",
    "        df = df[self.cols].dropna(axis=0)\n",
    "        return df[df['Low'] < self.max_low]\n",
    "\n",
    "    def format_file(self, path: str):\n",
    "        df = pd.read_csv(path)\n",
    "        df = self.filter_data(df)\n",
    "        return df.to_numpy().tolist()\n",
    "\n",
    "    def from_csvs(self, path):\n",
    "        files = self.get_all_csv_files(path)\n",
    "        loop = tqdm(files, total=len(files), leave=False)\n",
    "        return {self.ticker_from_path(path): self.format_file(path) for path in loop}\n",
    "\n",
    "    def load_datasets(self, Xpath: str, ypath: str, scl: dict):\n",
    "        assert os.path.isfile(Xpath), 'X file does not exist'\n",
    "        assert os.path.isfile(ypath), 'y file does not exist'\n",
    "\n",
    "        self.X: torch.Tensor = pickle.load(open(Xpath, 'rb'))\n",
    "        self.y: torch.Tensor = pickle.load(open(ypath, 'rb'))\n",
    "\n",
    "        assert self.X.shape[0] / self.time_d == self.X.shape[0] // self.time_d, 'time_d does not seem to be correct for this dataset'\n",
    "        assert self.y.shape[0] / self.output_params == self.y.shape[0] // self.output_params , 'the output_params seem to be incorrect for this dataset'\n",
    "        \n",
    "        self.X = self.X.reshape((self.X.shape[0] // self.time_d, self.time_d, self.X.shape[-1]))\n",
    "        self.y = self.y.reshape((self.y.shape[0] // self.output_params, self.output_params))\n",
    "\n",
    "        self.cl = scl\n",
    "        \n",
    "    def save_data(self, data: dict, path: str):\n",
    "        if os.path.isfile(path):\n",
    "            raise Exception('File already exists')\n",
    "\n",
    "        pickle.dump(data, open(path, 'wb'))\n",
    "\n",
    "        if self.compressed:\n",
    "            with open(path, 'rb') as f_in:\n",
    "                with gzip.open(path+'.gz', 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    def load_data(self, path: str):\n",
    "        if not os.path.isfile(path):\n",
    "            raise Exception('File does not exist')\n",
    "\n",
    "        data = None\n",
    "        if self.compressed:\n",
    "            with gzip.open(path, 'rb') as f_in:\n",
    "                with open(path.replace('.gz', ''), 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "        return pickle.load(open(path.replace('.gz', '') if self.compressed else path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "data = dp.from_csvs('./stock_market_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10479"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['AAPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.compressed = True\n",
    "dp.save_data(data, './data/dp.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dp.load_data('./data/dp.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Datasets\\stonks\\dataset.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Datasets/stonks/dataset.ipynb#ch0000039?line=0'>1</a>\u001b[0m dp\u001b[39m.\u001b[39;49mmake_datasets(data)\n",
      "\u001b[1;32me:\\Datasets\\stonks\\dataset.ipynb Cell 15\u001b[0m in \u001b[0;36mDataProcessor.make_datasets\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Datasets/stonks/dataset.ipynb#ch0000039?line=90'>91</a>\u001b[0m loop \u001b[39m=\u001b[39m tqdm(data, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(data), leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Datasets/stonks/dataset.ipynb#ch0000039?line=91'>92</a>\u001b[0m \u001b[39mfor\u001b[39;00m ticker \u001b[39min\u001b[39;00m loop:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Datasets/stonks/dataset.ipynb#ch0000039?line=92'>93</a>\u001b[0m     \u001b[39m# to_dataset\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Datasets/stonks/dataset.ipynb#ch0000039?line=93'>94</a>\u001b[0m     dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_dataset(data[ticker])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Datasets/stonks/dataset.ipynb#ch0000039?line=95'>96</a>\u001b[0m     \u001b[39m# checks\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Datasets/stonks/dataset.ipynb#ch0000039?line=96'>97</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(dataset[\u001b[39m0\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(dataset[\u001b[39m1\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mNone\u001b[39;00m):\n",
      "\u001b[1;32me:\\Datasets\\stonks\\dataset.ipynb Cell 15\u001b[0m in \u001b[0;36mDataProcessor.make_dataset\u001b[1;34m(self, d)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Datasets/stonks/dataset.ipynb#ch0000039?line=82'>83</a>\u001b[0m         yd \u001b[39m=\u001b[39m row\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Datasets/stonks/dataset.ipynb#ch0000039?line=83'>84</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Datasets/stonks/dataset.ipynb#ch0000039?line=84'>85</a>\u001b[0m         Xd \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mconcat((Xd, x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Datasets/stonks/dataset.ipynb#ch0000039?line=85'>86</a>\u001b[0m         yd \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mconcat((yd, row))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Datasets/stonks/dataset.ipynb#ch0000039?line=87'>88</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Xd, yd\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dp.make_datasets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.load_datasets('./data/Xlarge.bin', './data/ylarge.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24210020, 10, 5])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'money': (0.0, 1.0), 'volume': (0.0, 1.0)}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.scl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 44500.0) (0.0, 7421640800.0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def find_ranges(data: torch.Tensor):\n",
    "    money = data[:, :-1]\n",
    "    volume = data[:, -1:]\n",
    "\n",
    "    money_range = (float(torch.min(money)), float(torch.max(money)))\n",
    "    volume_range = (float(torch.min(volume)), float(torch.max(volume)))\n",
    "\n",
    "    return money_range, volume_range\n",
    "\n",
    "money_range, volume_range = find_ranges(torch.tensor(data.to_numpy()))\n",
    "print(money_range, volume_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(data: torch.Tensor, new_min=0, new_max=1):\n",
    "    global money_range\n",
    "    global volume_range\n",
    "    money = data[:, :4]\n",
    "    volume = data[:, -1:]\n",
    "\n",
    "    money = (money - money_range[0]) / (money_range[1] - money_range[0]) * (new_max - new_min) + new_min\n",
    "    volume = (volume - volume_range[0]) / (volume_range[1] - volume_range[0]) * (new_max - new_min) + new_min\n",
    "    return torch.hstack((money, volume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(df: torch.Tensor, time_d: int = 10):\n",
    "    Xd, yd = None, None\n",
    "\n",
    "    for i in range(df.shape[0] - time_d - 1):\n",
    "        idx = i + time_d\n",
    "        row = df[idx + 1]\n",
    "        row = row[:-1] # remove volume is it doesn't need to be predicted\n",
    "        x = df[i:idx]\n",
    "        if torch.isnan(torch.sum(x)) or torch.isnan(torch.sum(row)):\n",
    "            continue # if the row (y) has nans, skip\n",
    "\n",
    "        if type(Xd) == type(None):\n",
    "            Xd = x\n",
    "            yd = row\n",
    "        else:\n",
    "            Xd = torch.concat((Xd, x))\n",
    "            yd = torch.concat((yd, row))\n",
    "        \n",
    "    return Xd, yd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1363/4280 [24:10<42:59,  1.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ./stock_market_data/nasdaq\\csv\\CCUR.csv is useless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1551/4280 [27:57<1:08:53,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ./stock_market_data/nasdaq\\csv\\DXM.csv is useless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 1698/4280 [31:10<36:06,  1.19it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ./stock_market_data/nasdaq\\csv\\FSFF.csv is useless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2713/4280 [54:44<51:25,  1.97s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ./stock_market_data/nyse\\csv\\ACG.csv is useless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 2796/4280 [56:57<48:14,  1.95s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ./stock_market_data/nyse\\csv\\AVG.csv is useless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3108/4280 [1:06:03<19:29,  1.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ./stock_market_data/nyse\\csv\\FGL.csv is useless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3127/4280 [1:06:32<19:06,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ./stock_market_data/nyse\\csv\\FPT.csv is useless\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4280/4280 [1:55:26<00:00,  1.62s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "X, y = None, None\n",
    "\n",
    "loop = tqdm(files, total=len(files))\n",
    "for file in loop:\n",
    "    tmp = pd.read_csv(file)\n",
    "    tmp = tmp[['Low', 'Open', 'High', 'Close', 'Volume']].dropna()\n",
    "    tmp = tmp[tmp['Low'] < 5e3]\n",
    "\n",
    "    scaled = scale(torch.Tensor(tmp.to_numpy()))\n",
    "    dataset = make_dataset(scaled)\n",
    "\n",
    "    if type(dataset[0]) == type(None) or type(dataset[1]) == type(None):\n",
    "        print(f\"file {file} is useless\")\n",
    "        continue\n",
    "\n",
    "    if type(X) == type(None):\n",
    "        X = dataset[0]\n",
    "        y = dataset[1]\n",
    "    else:\n",
    "        X = torch.concat((X, dataset[0]))\n",
    "        y = torch.concat((y, dataset[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([242100200, 5])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X, open('./data/Xlarge.bin', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y, open('./data/ylarge.bin', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pickle.load(open('./data/X.bin', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6906777, 10, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape((6906777, 10, 5)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.Tensor(2, 7, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5939, 0.6351, 0.9802, 0.4510, 0.4155],\n",
       "         [0.1423, 0.9028, 0.1143, 0.7449, 0.7464],\n",
       "         [0.3748, 0.6898, 0.1778, 0.4913, 0.3977],\n",
       "         [0.8381, 0.5423, 0.1430, 0.4897, 0.9605],\n",
       "         [0.5049, 0.6050, 0.2317, 0.6488, 0.9490],\n",
       "         [0.9069, 0.8218, 0.7441, 0.8825, 0.8529],\n",
       "         [0.0739, 0.9540, 0.8932, 0.2987, 0.5890]],\n",
       "\n",
       "        [[0.1823, 0.8595, 0.1832, 0.9272, 0.9944],\n",
       "         [0.7184, 0.2080, 0.2378, 0.2978, 0.4247],\n",
       "         [0.2342, 0.6028, 0.7682, 0.6944, 0.3655],\n",
       "         [0.6381, 0.3703, 0.3003, 0.3945, 0.7956],\n",
       "         [0.4893, 0.5456, 0.0970, 0.7302, 0.4601],\n",
       "         [0.1616, 0.1483, 0.7895, 0.0596, 0.5900],\n",
       "         [0.3478, 0.8016, 0.8224, 0.1190, 0.4755]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hawkeye')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c22073af51062e6ad7b881550dba56f40a6b22c36a36ad35748461df38d8dc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
