{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500 = './stock_market_data/sp500/csv/'\n",
    "FILES = [os.path.join(SP500, file) for file in os.listdir(SP500)]\n",
    "EXCEPTIONS = []\n",
    "TIME_D = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "DEVICE = \"cuda\"\n",
    "EPOCHS = 10\n",
    "AS_DOUBLE = False\n",
    "WAB = False\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X, y):\n",
    "    div = 255 / np.max(X)\n",
    "    X *= div\n",
    "    y *= div\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(df: pd.DataFrame, time_d: int = 10):\n",
    "    X, y = [], []\n",
    "    last = []\n",
    "    for i, row in df.iterrows():\n",
    "        if row.hasnans:\n",
    "            if type(last) == type(None):\n",
    "                continue\n",
    "            row = last[-1] + (last[-1] - last[len(last) - 2]) / 2\n",
    "\n",
    "\n",
    "        if type(last) == type(None) or len(last) < time_d:\n",
    "            last.append(row.values)\n",
    "            continue\n",
    "        \n",
    "        X.append(np.array(last))\n",
    "        y.append(row.values)\n",
    "        last.pop(0)\n",
    "        last.append(row.values)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader_for_file(path: str):\n",
    "    df = pd.read_csv(path)\n",
    "    df.drop(['Date'], axis=1, inplace=True)\n",
    "    X, y = make_dataset(df, TIME_D)\n",
    "    X, y = scale(X, y)\n",
    "    if not AS_DOUBLE:\n",
    "        X, y = X.astype(\"float32\"), y.astype(\"float32\")\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "    train_loader = data.DataLoader(data.TensorDataset(torch.tensor(X_train), torch.tensor(y_train)), batch_size=BATCH_SIZE)\n",
    "    test_loader = data.DataLoader(data.TensorDataset(torch.tensor(X_test), torch.tensor(y_test)), batch_size=BATCH_SIZE)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod(val) : \n",
    "    res = 1 \n",
    "    for ele in val: \n",
    "        res *= ele \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, **kwargs):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, kernel_size=kernel_size, stride=stride, padding=padding, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.leakyrelu(self.batchnorm(self.conv(x)))\n",
    "\n",
    "    def outshape(self, w, h):\n",
    "        return int((h + 2 * self.padding - 1 * (self.kernel_size - 1) - 1) / self.stride + 1), int((w + 2 * self.padding - 1 * (self.kernel_size - 1) - 1) / self.stride + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, time_d: int = 10, n_outputs: int = 6):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        self.time_d = time_d\n",
    "        self.n_outputs = n_outputs\n",
    "        self.dropout = 0.1\n",
    "        self.n_filters = 32\n",
    "\n",
    "        self.cnn = CNNBlock(\n",
    "                    1,        # channels\n",
    "                    out_channels=self.n_filters,  # filters\n",
    "                    kernel_size=2,   # kernel size\n",
    "                    stride=2,        # stride\n",
    "                    padding=3,       # padding\n",
    "            )\n",
    "        self.cnn_bn = nn.BatchNorm2d(self.n_filters)\n",
    "\n",
    "        self.lstm = nn.LSTM(time_d, n_outputs, 2)\n",
    "        self.lstm_bn = nn.BatchNorm1d(n_outputs)\n",
    "\n",
    "        self.mid_neurons = (self.n_outputs ** 2) + (self.n_filters * prod(self.cnn.outshape(self.n_outputs, self.time_d)))\n",
    "        self.final = self._create_output_layers()\n",
    "\n",
    "    def _create_output_layers(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(self.mid_neurons, self.time_d * self.n_outputs),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(self.time_d * self.n_outputs, self.n_outputs)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        xa, (h_n, c_n) = self.lstm(x.reshape(-1, self.n_outputs, self.time_d))\n",
    "        xa = self.lstm_bn(xa)\n",
    "\n",
    "        xb = self.cnn(x.reshape(-1, 1, self.time_d, self.n_outputs))\n",
    "        xb = self.cnn_bn(xb)\n",
    "\n",
    "        xa = xa.reshape(-1, self.n_outputs * self.n_outputs)\n",
    "        xb = xb.reshape(-1, self.n_filters * prod(self.cnn.outshape(self.n_outputs, self.time_d)))\n",
    "\n",
    "        x = torch.hstack((xa, xb))\n",
    "\n",
    "        # forward through output layers and return\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLSTMLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        loss = self.mse(pred, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ConvLSTM(TIME_D, 6).to(DEVICE)\n",
    "if AS_DOUBLE:\n",
    "    m = m.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = ConvLSTMLoss()\n",
    "opt = torch.optim.Adam(m.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader):\n",
    "    losses = []\n",
    "\n",
    "    for x, y in loader:            \n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        out = m(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    if WAB:\n",
    "        wandb.log({\"loss\": int(np.mean(losses))})\n",
    "\n",
    "    return int(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(EPOCHS):\n",
    "        loop = tqdm(enumerate(FILES), total=len(FILES), leave=True)\n",
    "        for i, path in loop:\n",
    "            if path in EXCEPTIONS:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                train_loader, _ = get_loader_for_file(path)\n",
    "                mean_loss = train_fn(train_loader)\n",
    "                loop.set_postfix(loss=mean_loss) # update progress bar\n",
    "            except:\n",
    "                print(f'Something went wrong when processing file {path}. Adding it to the exceptions.')\n",
    "                EXCEPTIONS.append(path)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 50/413 [01:12<08:54,  1.47s/it, loss=14289]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong when processing file ./stock_market_data/sp500/csv/BEN.csv. Adding it to the exceptions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 51/413 [01:14<10:24,  1.72s/it, loss=3798] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong when processing file ./stock_market_data/sp500/csv/BHI.csv. Adding it to the exceptions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 57/413 [01:23<09:15,  1.56s/it, loss=2106]"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▆▅▅▄▃▃▃▃▃▂▃▂▂▂▂▂▁▂▂▂▂▁▁▂▁▁▁▁▁▁▁▂▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>673</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sunny-tree-6</strong>: <a href=\"https://wandb.ai/seppedelanghe/Stonks/runs/k5dxgfbu\" target=\"_blank\">https://wandb.ai/seppedelanghe/Stonks/runs/k5dxgfbu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220712_151818-k5dxgfbu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep():\n",
    "    with wandb.init(project='Stonks', entity=\"seppedelanghe\") as run:\n",
    "        config = wandb.config\n",
    "        LR = config['lr']\n",
    "        TIME_D = config['time_d']\n",
    "\n",
    "        for epoch in range(config['epochs']):\n",
    "            loop = tqdm(enumerate(FILES), total=len(FILES), leave=True)\n",
    "            for i, path in loop:\n",
    "                if path in EXCEPTIONS:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    train_loader, _ = get_loader_for_file(path)\n",
    "                    mean_loss = train_fn(train_loader)\n",
    "                    loop.set_postfix(loss=mean_loss) # update progress bar\n",
    "                except:\n",
    "                    print(f'Something went wrong when processing file {path}. Adding it to the exceptions.')\n",
    "                    EXCEPTIONS.append(path)\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 9j4my0r7\n",
      "Sweep URL: https://wandb.ai/seppedelanghe/uncategorized/sweeps/9j4my0r7\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "sweep_config = {\n",
    "  \"name\" : \"initial-sweep\",\n",
    "  \"method\" : \"random\",\n",
    "  \"parameters\" : {\n",
    "    \"epochs\" : {\n",
    "      \"values\" : [2, 3, 4, 5]\n",
    "    },\n",
    "    \"lr\" :{\n",
    "      \"min\": 0.0001,\n",
    "      \"max\": 0.1\n",
    "    },\n",
    "    \"time_d\": {\n",
    "        \"min\": 3,\n",
    "        \"max\": 15\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 07i1o23r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.040622029510542584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_d: 12\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\Datasets\\stonks\\wandb\\run-20220712_214757-07i1o23r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/seppedelanghe/uncategorized/runs/07i1o23r\" target=\"_blank\">revived-sweep-2</a></strong> to <a href=\"https://wandb.ai/seppedelanghe/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/seppedelanghe/uncategorized/sweeps/9j4my0r7\" target=\"_blank\">https://wandb.ai/seppedelanghe/uncategorized/sweeps/9j4my0r7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 54/413 [01:19<09:52,  1.65s/it, loss=3211] "
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=sweep, count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fn(loader):\n",
    "    results = None\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE)\n",
    "        y_pred = m(x)\n",
    "        \n",
    "        y_pred = y_pred.to('cpu').detach().numpy()\n",
    "        y = y.to('cpu').detach().numpy()\n",
    "        if type(results) == type(None):\n",
    "            results = np.array((y, y_pred))\n",
    "        else:\n",
    "            results = np.hstack((results, np.array((y, y_pred))))\n",
    "\n",
    "    return results.reshape((results.shape[1], 2, results.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_loader = get_loader_for_file(FILES[0])\n",
    "results = test_fn(test_loader)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 2, 6)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99996116e-05, 1.02332646e-04, 1.17280900e+01, 1.04111587e-04,\n",
       "        1.00582874e-04, 9.14977158e-05],\n",
       "       [5.15411116e-04, 5.20915026e-04, 6.57249069e+00, 5.25032779e-04,\n",
       "        5.17775769e-04, 5.13273684e-04]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0 17  0  0  0]\n",
      " [ 0  0 13  0  0  0]\n",
      " [ 0  0 11  0  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  9  0  0  0]\n",
      " [ 0  0 11  0  0  0]\n",
      " [ 0  0  9  0  0  0]\n",
      " [ 0  0  9  0  0  0]\n",
      " [ 0  0  8  0  0  0]\n",
      " [ 0  0 10  0  0  0]]\n",
      "[[ 0  0 10  0  0  0]\n",
      " [ 0  0  7  0  0  0]\n",
      " [ 0  0  6  0  0  0]\n",
      " [ 0  0  7  0  0  0]\n",
      " [ 0  0  7  0  0  0]\n",
      " [ 0  0  6  0  0  0]\n",
      " [ 0  0  4  0  0  0]\n",
      " [ 0  0  9  0  0  0]\n",
      " [ 0  0  7  0  0  0]\n",
      " [ 0  0  8  0  0  0]]\n",
      "[[ 0  0 16  0  0  0]\n",
      " [ 0  0 21  0  0  0]\n",
      " [ 0  0 11  0  0  0]\n",
      " [ 0  0 11  0  0  0]\n",
      " [ 0  0 19  0  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0 24  0  0  0]\n",
      " [ 0  0 69  0  0  0]\n",
      " [ 0  0 20  0  0  0]\n",
      " [ 0  0 19  0  0  0]]\n",
      "[[ 0  0 12  0  0  0]\n",
      " [ 0  0 13  0  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0 13  0  0  0]\n",
      " [ 0  0 11  0  0  0]\n",
      " [ 0  0 10  0  0  0]\n",
      " [ 0  0 29  0  0  0]\n",
      " [ 0  0 14  0  0  0]\n",
      " [ 0  0  8  0  0  0]\n",
      " [ 0  0  8  0  0  0]]\n",
      "[[ 0  0  7  0  0  0]\n",
      " [ 0  0  8  0  0  0]\n",
      " [ 0  0  7  0  0  0]\n",
      " [ 0  0 14  0  0  0]\n",
      " [ 0  0 13  0  0  0]\n",
      " [ 0  0  9  0  0  0]\n",
      " [ 0  0 10  0  0  0]\n",
      " [ 0  0  6  0  0  0]\n",
      " [ 0  0 21  0  0  0]\n",
      " [ 0  0 18  0  0  0]]\n",
      "[[ 0  0  9  0  0  0]\n",
      " [ 0  0  6  0  0  0]\n",
      " [ 0  0  6  0  0  0]\n",
      " [ 0  0  4  0  0  0]\n",
      " [ 0  0  5  0  0  0]\n",
      " [ 0  0  4  0  0  0]\n",
      " [ 0  0  3  0  0  0]\n",
      " [ 0  0 13  0  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0 12  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y in test_loader:\n",
    "    x = x.detach().numpy()\n",
    "    x = np.rint(x).astype('uint8')\n",
    "    for i in range(len(x)):\n",
    "        if i > 5:\n",
    "            break\n",
    "        \n",
    "        bx, by = x[i], y[i]\n",
    "        print(bx)\n",
    "        plt.imshow(bx)\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(m.state_dict(), './sp500_413_loss_688.tar.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvLSTM()\n",
    "model.load_state_dict(torch.load('./sp500_413_loss_688.tar.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTM(\n",
       "  (cnn): CNNBlock(\n",
       "    (conv): Conv2d(1, 32, kernel_size=(2, 2), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (cnn_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lstm): LSTM(10, 6, num_layers=2)\n",
       "  (lstm_bn): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (final): Sequential(\n",
       "    (0): Linear(in_features=1572, out_features=60, bias=True)\n",
       "    (1): Dropout(p=0.1, inplace=False)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "    (3): Linear(in_features=60, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hawkeye')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c22073af51062e6ad7b881550dba56f40a6b22c36a36ad35748461df38d8dc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
